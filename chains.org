#+TITLE: Experiment Chains
#+AUTHOR: Mark Cox

~CHAINS~ is a common lisp system for constructing an experiment chain
in which a number of links are assembled to produce a result. Its main
purpose is to accommodate scenarios where the line between a
scientific experiment and algorithmic experimentation is blurred.

[TABLE-OF-CONTENTS]

* A backstory
This section outlines the main use case for the ~CHAINS~ system. The
abstraction the ~CHAINS~ system employs is rather strange when
introduced on its own. Hopefully this section aids in understanding
why. The example presented in this section is real, and is the primary
reason for the existence of the ~CHAINS~ system.

An important problem in the field of computer vision is that of
/congealing/. The task of congealing is very simple, discover the
location of an object contained in an ensemble of images. A key trait
of congealing algorithms is that they know nothing about the object in
each image, other than it can be assumed that the object is present in
each image. A concrete example of congealing would be, given an
ensemble of images containing faces, find me the bounding box of each
face.

When evaluating a congealing algorithm one must evaluate the algorithm
against the following criteria
- Level of initial misalignment :: How far away from the true location
     can then algorithm correctly locate the object?
- Lighting variation :: How does the algorithm handle variation in
     appearance due to illumination conditions?
- Image noise :: How does the algorithm handle variation in appearance
                 due to image noise?
- Appearance variation :: How does the algorithm handle variation in
     appearance of the object? For faces, this would mean male versus
     female, beard versus non-beard, and so on.
- Occlusion :: How does the algorithm handle cases where the object is
               occluded by another object? e.g. a face occluded by
               hair, glasses or another object.
- Ensemble size :: How does the number of images in the ensemble
                   influence performance?
- Cross validation on images :: Testing performance on another ensemble of
     images with exactly the same statistics.
- Cross validation on geometry :: Testing performance on the same
     collection of images but with different random starting
     locations.

It is fine if you do not understand all of the above. The key point is
that they are /variables/ or statistics measured on the ensemble of
images fed to the congealing algorithm. Congealing algorithms behave
differently depending on the value of each variables. In fact, even a
different ensemble with the same statistics can behave
differently.

In addition to variables associated with the input data, a congealing
algorithm typically has a number of parameters that influence its own
performance. These parameters have a range of values that are "worth"
trying, with the best value selected at the end by some means.

One also must compare the algorithm against another algorithm on
/exactly/ the same image ensemble. Having exactly the ensemble is
extremely important as a strategically chosen change can have a
dramatic effect on performance for some algorithms.

Once all of the algorithms are executed, a results collation process
begins. The results obtained depend on the report or paper that is
being written. These results may involve performance conditioned on
the statistics of the image ensemble, or the amount of influence an
algorithm parameter has on the overall algorithm performance.

Everything up to this point is straight forward. You prepare the image
ensemble to be fed to all congealing algorithms, execute each
algorithm, prepare the results and then write the report/paper. Easy.

Immediately we see that the algorithm and the experiments to be
performed are not concrete. One typically creates many algorithms that
may "do the job", but one does not know whether it is an idea worth
investigating further until it has been implemented and a preliminary
set of results are obtained. Additionally, the type of results
required may change depending on the point being made.

Unfortunately, this rarely occurs in practice. In practice, one
implements an algorithm that has been published. Upon experimenting
(or implementing) with the algorithm, it is discovered that there is
something that could be improved. For example, the algorithm cannot
handle image ensembles with certain statistics or the algorithm is
really sensitive to a particular parameter or the algorithm is flawed
in some manner. With this new information, the goal now is to
empirically confirm the identified problem and design a new algorithm
that can overcome the identified problem.

What a scientist wants to work on is the algorithm. That is what is
important. That is what is publishable. The experiment stuff validates
the argument for the algorithm, but it is not the primary focus. 

Saying it is not of primary focus is rather ironic. The experiment
design is what lead to the discovery. The experiment design also
validates a new discovery. Furthermore, it is the experiment design
where much of a computer scientist's effort is spent and it is to easy
to see why.

The problem with experiments is that they take time to execute and to
implement. The long execution time is because the number of
experiments is a combinatorial function defined by the number of
values specified for each experiment parameter. i.e. if you have a
large number of experiment parameters and a large number of values per
experiment parameter then you have an /extremely/ large number of
experiments.

Fortunately, since the experiments are independent, they can be
executed in parallel. Well, not quite in parallel as described later,
but the experiment execution problem does belong to the class of
embarrassingly parallelisable problems.

Another difficulty is collating results. When writing a report or a
paper, one typically needs additional graphs (or tables, but who likes
tables?) that were not thought of initially. To accommodate this use
case, the output of the experiments should be saved in order to save
(valuable) time. This serialisation not only applies to the algorithm
output and input, but for all data computed in the experiment.

This database of serialised experiment data also needs to have the
ability to be queried. This ability is needed by the results collation
step mentioned previously.

All of this is simple to state, but is moderately difficult to
implement and very easy to make simple mistakes which are hard to
identify. Additionally, the code that performs the experiment setup,
execution and result collation very rarely receive the level of
attention and care that algorithms receive. In my local minima which
is termed life, I have not seen released code that just performs
experiments. Why? Great question.

The ~CHAINS~ system attempts to provide facilities for the above tasks
in order for the scientist to spend more time on developing an
understanding of existing algorithms and to develop new algorithms
that overcome identified issues.

Lastly, the ~CHAINS~ is not a plug and play work flow optimiser where
one only performs plumping. It should not be a dependency in your
algorithm implementations. The only place where the ~CHAINS~ system
should be used is in verifying and validating an algorithm's
performance on different types of data and collating algorithm results
for some sort of publication.

* Concepts and mental models
The background section painted a picture of the aspects of the problem
the ~CHAINS~ system attempts to address. This section attempts to
illustrate more of the core concepts that underpin the library.

Performing a single experiment is really the serial execution of a
number of tasks. For the congealing problem outlined above, the
high-level tasks are as follows
#+begin_src ditaa :file congealing-tasks.png
+------------+
| Input Data |
+-----+------+
      |
      v
+-----------+
| Algorithm |
+-----+-----+
      |
      v
  +--------+
  | Metric |
  +--------+
#+end_src
The input data task is responsible for creating the ensemble of images
fed to the algorithm. Once the algorithm has provided an estimate of
the object's position, this position is then compared to the ground
truth using a metric. The metric provides a quantitative measure of
the algorithm's performance.

This linking of tasks to be executed is termed a task chain, or just a
chain.

A collection of experiments to be executed is really a tree. Consider
the following figure where there are two congealing algorithms being
evaluated on two different sets of input data.
#+begin_src ditaa :file parallelism.png
+--------------+     +-------------+   +--------+
| Input Data 1 +-+-->| Algorithm 1 |-->| Metric |
+--------------+ |   +-------------+   +--------+
                 |
                 |   +-------------+   +--------+
                 +-->| Algorithm 2 |-->| Metric |
                     +-------------+   +--------+

+--------------+     +-------------+   +--------+
| Input Data 2 +-+-->| Algorithm 1 |-->| Metric |
+--------------+ |   +-------------+   +--------+
                 |
                 |   +-------------+   +--------+
                 +-->| Algorithm 2 |-->| Metric |
                     +-------------+   +--------+
#+end_src
The above figure presents two trees which start from an input data
task. The ~CHAINS~ system inserts a "start here" root task in order to
produce a single tree. The key property of the tree is that a path
from the root task to a leaf represents a single experiment or task
chain.

The tree view of the experiments also highlights the parallelism of
the experiment execution. Once a task is completed, all of its
children can be executed in parallel.

The ~CHAINS~ system does not limit the length of the chain, nor is
there any requirement that all leaves should have the same distance to
the root task. In fact the ~CHAINS~ system does not provide any
default tasks as tasks are fundamentally problem specific. What the
~CHAINS~ system does provide is a mechanism for constructing a new
tree, discovering an existing tree, executing a tree, tree
serialisation and querying.

Another important characteristic of tasks is the way they
interact. The ~CHAINS~ system assumes that a task can only depend on
output from previous tasks in the chain. This is shown in the next
figure for the congealing problem.
#+begin_src ditaa :file algorithm-input.png
    +---------------------------+
    | Synthesize Image Ensemble |
    +----+----------------------+
         |
+--------+
|        |
|        v
|   +--------------------------+
|   | Synthesize Initial Guess |
|   +----+---------------------+
|        |
+-----+  |
      |  |
      v  v
    +-----------+
    | Algorithm |
    +-----------+
#+end_src
As you can see, the input to the algorithm requires data from the
task(s) that synthesize the image ensemble and the task(s) that
synthesize the initial guess. The above diagram is no longer a chain,
it is a directed graph. How the ~CHAINS~ system models the above graph
is by distinguishing between the operation to be performed, and the
input and output of that operation. The goal of the ~CHAINS~ system is
to allow tasks to be reusable. How tasks form a chain is dependent on
the experiment design and is by definition not reusable across
designs.



* Serialisation
The serialisation strategy employed in the ~CHAINS~ system is a very
simple system involving only the lisp pretty printer
(~*PRINT-READABLY*~ is ~T~) as the data format, and only files and
directories on the storage device. 

Each node of an experiment tree has its own directory in order to
store the task parameters, the task value generated by a tasks
operation and other task specific data. The name of this directory is
computed using the function ~TASK-STRING~.
#+begin_src lisp
(defgeneric task-string (task))
#+end_src

A default implementation of ~TASK-STRING~ exists for all tasks. Example
output for the task is as follows
#+begin_src lisp
  (define-task example-task ()
    ((sigma
      :initarg :sigma
      :reader sigma)
     (rho
      :initarg :rho
      :reader rho)))
  
  (task-string (make-instance 'example-task :sigma 0.5 :rho 1.1))
  ;; "example-task-0.5-1.1"
#+end_src
Slot values for a task that has superclasses will appear after the
slot values for the superclasses.

Serialisation of tasks is performed using the function
~SERIALISE-TASK~. This function produces a string that when read and
evaluated, produces a new instance of the task which is considered
/equal/ to the task that was serialised. This process is similar to
the ~*PRINT-READABLY*~ functionality, but does not directly rely on
~PRINT-OBJECT~. 
#+begin_src lisp
  (defun serialise-task (stream task))
#+end_src

~SERIALISE-TASK~ iterates through all slots of the task,
transforming each slot value in to an s-expression which evaluates to
an /equal/ object. Customisation of the generated expression for a
given object is provided by the ~OBJECT-SEXP~ generic function.
#+begin_src lisp
  (defgeneric object-sexp (object))
#+end_src

If no ~OBJECT-SEXP~ method exists for ~OBJECT~, then ~PRINT-OBJECT~ is
invoked with ~*PRINT-READABLY*~ bound to ~T~.

* Querying
Querying a set of experiments is critical to the collation of
results. When a set of experiments have finished executing, the
experiment chains can be discovered using the function
~DISCOVER-CHAINS~.
#+begin_src lisp
  (defun discover-chains (pathname))
#+end_src
This function returns a list of lists where each list contains the
tasks that formed the experiment. In this section, the term chain
represents an item and the term chains is a sequence of chains.

The function ~CONTAINS-TASK-P~ can be used to determine if a chain
contains task which is a subclass of ~TASK-CLASS~.
#+begin_src lisp
  (defun contains-task-p (chain task-class))
#+end_src

The function ~FIND-CHAINS-WITH-TASK~ returns all chains in which
~CONTAINS-TASK-P~ is ~T~ for the given task.
#+begin_src lisp
  (defun find-chains-with-task (chains task-class))
#+end_src

Another important function is ~GROUP-BY~, which can group tasks
together according to given a test.
#+begin_src lisp
  (defun group-by (sequence test &key key))
#+end_src

In practice, the ~GROUP-BY~ function is needed so frequently and
coupled so tightly with the tasks, that a special function
~GROUP-CHAINS~ is provided. The ~GROUP-CHAINS~ function works in
conjunction with information specified when defining a task.
#+begin_src lisp
    (defun group-chains (chains expression &key sort inner-sort))
#+end_src
An ~EXPRESSION~ is a form which is used to synthesize a predicate for
~GROUP-BY~. 

Valid expressions are 
- ~symbol~ :: Group chain items together according to the subclasses
              of ~SYMBOL~. e.g. all congealing algorithm tasks inherit
              from ~ALGORITHM~, thus specifying ~(quote ALGORITHM)~
              would group all chains that use the same algorithm.
- ~(= symbol)~ :: Group chain items together according to the
                  subclasses of ~SYMBOL~ and ensure every task is
                  equal.
- ~(= symbol name)~ :: This expression specifies that the chains
     within a group all have the same value for the slot ~NAME~ in the
     task with type ~SYMBOL~.

The last expression ~(= symbol name)~ does not use the function ~=~,
but rather it obtains an arity two predicate using the
~:PREDICATES~ slot definition argument used within
~DEFINE-TASK~. 

Predicates represent a collection of comparison functions for a
specific type of value. The predicates for built-in ~NUMBER~ are
defined as follows.
#+begin_src lisp
  (define-predicates number #'= #'< #'>)
#+end_src
The functions can be obtained using generic functions
#+begin_src lisp
  (defgeneric test=-function (name))
  (defgeneric test<-function (name))
  (defgeneric test>-function (name))
#+end_src

Other built-in predicates provided are ~STRING/CASE-SENSITIVE~ and
~STRING/CASE-INSENSITIVE~.

The task definition for ~GEOMETRIC-CROSS-VALIDATION~ including the
test predicates would be
#+begin_src lisp
  (define-task geometric-cross-validation ()
    ((sample
      :initarg sample
      :reader sample
      :predicates number
      :documentation "The index of the random sample.")))
#+end_src
This states the equality predicate synthesised by ~GROUP-CHAINS~ would
use the ~TEST=-FUNCTION~ function from the ~NUMBER~ predicates
definition, which is in this case is actually the function ~=~.

The keyword arguments ~SORT~ and ~INNER-SORT~ of the ~GROUP-CHAINS~
function perform sorting of the groups and the chains within the
groups according to a sort expression. A sort expression can be one of
- ~(> symbol name)~ :: Like the ~=~ expression previously, but using
     the ~TEST>-FUNCTION~ predicate.
- ~(< symbol name)~ :: Similar to the ~>~ expression.
- ~(:classes &rest task-class-names)~ :: Order tasks according to
     their order of appearance in ~TASK-CLASS-NAMES~. It is an error
     if a task is found which does not inherit from any class in
     ~TASK-CLASS-NAMES~.
- ~(:group-by expression)~ :: Sort the chains by grouping them
     according to the grouping expression ~EXPRESSION~.

If the same expression and sort expression arguments are being
repeatedly passed to ~GROUP-CHAINS~ consider using the function
~PREPARE-GROUP-CHAINS~.
#+begin_src lisp
(defun prepare-group-chains (expression &key sort inner-sort))
#+end_src

* Generating
This section outlines the process of generating and documenting a set
of experiments.

Creating a set of experiments requires two steps. The first step is
specifying the experiment design using the ~DEFINE-DESIGN~ macro. The
second step is generating the experiment tree using the function
~GENERATE~. It is important to understand that the design document
only contains the information needed to generate the tree, it does not
contain the experiments themselves.

The macro ~DEFINE-DESIGN~ is as follows
#+begin_src lisp
  (defmacro define-design (name design-options &body levels))
#+end_src
The argument ~NAME~ is a symbol naming the design that is being
defined. ~DEFINE-OPTIONS~ is a list of design options that will be
covered throughout this section. The important argument, ~LEVELS~,
contains information about the hierarchy of the tree.

A diagram illustrating what ~LEVELS~ in ~DEFINE-DESIGN~ 
#+begin_src ditaa :file levels.png
                               +--------------+
                               | Root of Tree |
                               +----+-+-+-----+
                                    | | |
                          +---------+ | +-----------------+
                          |           |                   |
                          v           v                   v
                    +----------+ +----------+       +------------+
  Level 0           | Task 0 0 | | Task 0 1 |  -=-  | Task 0 M_0 |
                    +----+-----+ +----+-----+       +-----+------+
                         |            |                   |
                         v            v                   v
              +---------------+ +---------------+ +---------------+
              | Level 1 Tasks | | Level 1 Tasks | | Level 1 Tasks |
              +-+-----+-----+-+ +-+-----+-----+-+ +-+-----+-----+-+
                |     |     |     |     |     |     |     |     |
                v     v     v     v     v     v     v     v     v                 
#+end_src
The first item of ~LEVELS~, level 0, contains information about
generating the children of the root node. In other words, the children
of the root node represent the first tasks to be executed in each
experiment chain. The second item of ~LEVELS~ contains information
about generating the children for each of the first children in
level 0. In essence, a level represents the tasks that are to be added
to each leaf in the tree constructed from the previous levels.

Each element of ~LEVELS~ is a level definition expression. Examples of
these forms can be seen in an example design used for the congealing
problem
#+begin_src lisp
  (define-design congealing
    ((:documentation "A set of experiments for the paper XYZ."))
  
    ;; Images
    ((image-appearance-and-lighting (:lighting-variation 0 0.1 0.2 0.3 0.4)
                                    (:number-of-subjects 1 2 5 10 20)
                                    (:samples-per-subject 1 5 10)))
  
    ((image-cross-validation (:sample (:splice (loop :for x :from 0 :below 10 :collect x)))))
  
    ((synthetic-occlusion (:count 0 1 2)
                          (:size 0.5 0.1 0.2)))
  
    ;; Initial guess of object location
    ((distance-away-from-ground-truth (:distance 2 5 10 15)))
  
    ((geometric-cross-validation (:sample 0 1 2)))
  
    ;; Algorithms to be executed
    ((learned-miller (:deltas '(1 1 0.1 0.1 1 1)))
     least-squares-congealing
     rasl)
    
    ;; Results to be computed.
    (alignment-performance))
#+end_src
A level definition is a list containing generate expressions, where a
generate expression specifies the tasks to generate. When the tasks
for each generate expression have been generated, they are appended
together to form the list of tasks that are to be appended to each
leaf in the current experiment tree.

Lets consider what the generate expression in the level 0 definition
means.
#+begin_src lisp
  (image-appearance-and-lighting (:lighting-variation 0 0.1 0.2 0.3 0.4)
                                 (:number-of-subjects 1 2 5 10 20)
                                 (:samples-per-subject 1 5 10))
#+end_src
This expression states that the following list of tasks are to be
generated.
#+begin_src lisp
  (list (make-instance 'image-appearance-and-lighting
                       :lighting-variation 0
                       :number-of-subjects 1
                       :samples-per-subject 1)
        (make-instance 'image-appearance-and-lighting
                       :lighting-variation 0.1
                       :number-of-subjects 1
                       :samples-per-subject 1)
        ...
        (make-instance 'image-appearance-and-lighting
                       :lighting-variation 0.4
                       :number-of-subjects 20
                       :samples-per-subject 10))
#+end_src
Thus there exists an instance of the task
~IMAGE-APPEARANCE-AND-LIGHTING~ for every permutation of the argument
values for the slots ~:LIGHTING-VARIATION~, ~:NUMBER-OF-SUBJECTS~ and
~:SAMPLES-PER-SUBJECT~.

The previous generate expression illustrates some basic
functionality. The generate expression for level 1 illustrates some
more advanced capabilities.
#+begin_src lisp
(image-cross-validation (:sample (:splice (loop :for x :from 0 :below 10 :collect x))))
#+end_src

The ~:SPLICE~ keyword operator evaluates the form ~(loop :for x :from
0 :below 10 :collect x)~ and splices it in place to produce the
following equivalent expression.
#+begin_src lisp
  (image-cross-validation (:sample 0 1 2 3 4 5 6 7 8 9))
#+end_src
It should be noted that the evaluation only occurs during ~GENERATE~
and not when the design is created.

The expression involving the algorithms represents the following
children
#+begin_src lisp
  (list (make-instance 'learned-miller
                       :deltas '(1 1 0.1 0.1 1 1)
                       :maximum-number-of-iterations 100)
        (make-instance 'least-squares-congealing
                       :maximum-number-of-iterations 10)
        (make-instance 'rasl
                       :maximum-number-of-iterations 10))
#+end_src

A special generate expression ~(:design design-name)~ is provided to
allow trees with leaves at different depths. For example, the
~CONGEALING~ design could be written as follows.
#+begin_src lisp
  (define-design congealing/input-data
      ...)
  (define-design congealing/algorithms
      ...)
  (define-design congealing/results
      ...)
  
  (define-design congealing
    (:documentation "The complete set of experiments for congealing.")
  
    ((:design congealing/input-data))
  
    ((:design congealing/algorithms))
  
    ((:design congealing/results)))
#+end_src
The ~:DESIGN~ generate expression also permits some reuse of
experiment designs.

The function ~GENERATE~ is used to create the experiments defined with
the ~DEFINE-DESIGN~ macro. 
#+begin_src lisp
(defun generate (design-name))
#+end_src
This function returns a ~TREE~ containing the entire collection of
experiments.
* Executing
Before a tree of experiments is executed, an area to store the tree
and each task results must be prepared. The function ~PREPARE~
performs this task.
#+begin_src lisp
  (defgeneric prepare (directory tree &key if-exists))
#+end_src
The argument ~IF-EXISTS~ determines what to do if there exists tasks
in ~DIRECTORY~ that would be overwritten. ~IF-EXISTS~ can be one of
~:ERROR~, ~:SUPERSEDE~ or ~:SKIP~. Since a chain is also a tree, the
~PREPARE~ function can accept objects of type ~CHAIN~.

If a directory has already been prepared then the function
~DISCOVER-TREE~ can be executed to obtain the tree.
#+begin_src lisp
  (defun discover-tree (pathname))
#+end_src

A task's operation can not be executed directly as it is conditioned
on other tasks in the chain. The function ~PERFORM-LEAF~ executes the
task at the end of the chain.
#+begin_src lisp
  (defgeneric perform-leaf (area chain &key force &allow-other-keys))
#+end_src
The ~AREA~ argument specifies a prepared area in which to store the
results. The ~CHAIN~ argument is the chain whose leaf is to be
executed. The keyword argument ~FORCE~, specifies that the task should
be executed, overwriting any existing output.

An operation can obtain the value of the ~FORCE~ argument via the
~*FORCED*~ dynamic variable. Other keyword arguments passed to
~PERFORM-LEAF~ can be retrieved using the function ~OPERATION-PLIST~.
#+begin_src lisp
  (defvar *forced*)
  
  (defun operation-plist ())
#+end_src

Associated with the ~PERFORM-LEAF~ function is the function
~PERFORM~. This function executes all tasks in the chain.
#+begin_src lisp
  (defgeneric perform (area chain &key force &allow-other-keys))
#+end_src

** Execution parameters
The above execution model works well for most tasks. There is a class
of tasks which unfortunately do not fit this model and require special
mention (and attention in ~CHAINS~).

The class of tasks are those that execute an iterative algorithm whose
output is continually reprocessed until some sort of criteria is met
e.g. non-linear optimisation.

It is tempting to write tasks like this
#+begin_src lisp
  (define-task iterative-algorithm ()
    ((number-of-iterations
      ...)))
#+end_src
The problem with this is that you are implicitly assuming that
~NUMBER-OF-ITERATIONS~ is the maximum number of iterations that you
will ever need to execute. If you change ~NUMBER-OF-ITERATIONS~, then
the task has to start from the beginning because the ~TASK-NAME~ will
change.

More importantly, ~NUMBER-OF-ITERATIONS~ is not an experiment
parameter. It does change the result of the task, but it is a measure
like the amount of appearance variation experiment measure found in
congealing. 

We now outline the recommended way of implementing these types of
tasks.

The first step is to introduce the /execution/ parameter as a dynamic
variable.
#+begin_src lisp
  (defvar *number-of-iterations* 10)
#+end_src

Specifying the number of iterations to execute impacts the ~CHAINS~
system's method of determining whether a task is finished or not. 

The generic function responsible for determining whether a task has
been completed is the function ~TASK-COMPLETED-P~.
#+begin_src lisp
  (defgeneric task-completed-p (task))
#+end_src

This method can be implemented for a specific task which checks that
the correct number of iterations have been executed.
#+begin_src lisp
  (defmethod task-completed-p ((task iterative-algorithm))
    (and (probe-file (iteration-output task *number-of-iterations*))
         (call-next-method)))
#+end_src

The ~TASK-COMPLETED-P~ generic function has no support for altering
the implementation based on the tasks in the chain as is the case for
~DEFINE-OPERATION~. This behaviour is considered an abuse of the
~CHAINS~ system. All operations should produce similar outputs and
behave similarly as well.

The operation for the task is then responsible for determining the
previous iterations output to reprocess.
